{
 "cells": [
  {
   "cell_type": "raw",
   "id": "263be8a1",
   "metadata": {},
   "source": [
    "Design and implement a CNN for Image Classification a) Select a suitable image classification \n",
    "dataset (medical imaging, agricultural, etc.). b) Optimized with different hyper-parameters including \n",
    "learning rate, filter size, no. of layers, optimizers, dropouts, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08cf9002",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pajag\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\pajag\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.4sp5sua7cbgxueoc35yp2asoicyyeqzz.gfortran-win_amd64.dll\n",
      "C:\\Users\\pajag\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense,Conv2D,Dropout,MaxPooling2D,Flatten\n",
    "from tensorflow.keras import models,Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e327843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(folder_path):\n",
    "    img_name = os.listdir(folder_path)\n",
    "    img = []\n",
    "    i = 0\n",
    "    for name in img_name:\n",
    "        if i < 100:\n",
    "            image = cv2.imread(os.path.join(folder_path,name))\n",
    "            img.append(image)\n",
    "            i+=1\n",
    "    return np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b21e5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-08a29b18ba9b>:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(img)\n"
     ]
    }
   ],
   "source": [
    "train_t = load_img('C://Users//pajag//OneDrive//Desktop//img apple & tomato//train//tomatoes')\n",
    "train_a = load_img('C://Users//pajag//OneDrive//Desktop//img apple & tomato//train//apples')\n",
    "test_t = load_img('C://Users//pajag//OneDrive//Desktop//img apple & tomato//test//tomatoes')\n",
    "test_a = load_img('C://Users//pajag//OneDrive//Desktop//img apple & tomato//test//apples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf78a55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100,), (100,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_a.shape,train_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a7b32f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54,), (43,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_a.shape,test_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38287b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (64,64)\n",
    "def preprocess(arr):\n",
    "    resize = []\n",
    "    for img in arr:\n",
    "        img = cv2.resize(img,img_size)\n",
    "        img = img/255\n",
    "        resize.append(img)\n",
    "    return resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3688f0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a_preprocess = preprocess(train_a)\n",
    "train_t_preprocess = preprocess(train_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2b961a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_a_preprocess = preprocess(test_a)\n",
    "test_t_preprocess = preprocess(test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3804768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1bf7008",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a_df = pd.DataFrame({'images':train_a_preprocess,'label':'0'})\n",
    "train_t_df = pd.DataFrame({'images':train_t_preprocess,'label':'1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fec67577",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_a_df = pd.DataFrame({'images':test_a_preprocess,'label':'0'})\n",
    "test_t_df = pd.DataFrame({'images':test_t_preprocess,'label':'1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "818d39c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.concat([train_a_df,train_t_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6318f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.concat([test_a_df,test_t_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90be9ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.iloc[np.random.permutation(len(data_train))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aaf83a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_test.iloc[np.random.permutation(len(data_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6658ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[[0.9254901960784314, 0.9568627450980393, 0.9...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[[[0.10196078431372549, 0.1450980392156863, 0....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>[[[0.996078431372549, 0.984313725490196, 0.996...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[0.6862745098039216, 0.7098039215686275, 0.7...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[[[0.5568627450980392, 0.7568627450980392, 0.7...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               images label\n",
       "9   [[[0.9254901960784314, 0.9568627450980393, 0.9...     0\n",
       "26  [[[0.10196078431372549, 0.1450980392156863, 0....     0\n",
       "85  [[[0.996078431372549, 0.984313725490196, 0.996...     1\n",
       "2   [[[0.6862745098039216, 0.7098039215686275, 0.7...     0\n",
       "18  [[[0.5568627450980392, 0.7568627450980392, 0.7...     1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b465739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[[[0.00392156862745098, 0.00392156862745098, 0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[[[0.9450980392156862, 0.9215686274509803, 0.8...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[[[0.4588235294117647, 0.47058823529411764, 0....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[0.09411764705882353, 0.3333333333333333, 0....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               images label\n",
       "36  [[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0,...     0\n",
       "23  [[[0.00392156862745098, 0.00392156862745098, 0...     0\n",
       "37  [[[0.9450980392156862, 0.9215686274509803, 0.8...     0\n",
       "36  [[[0.4588235294117647, 0.47058823529411764, 0....     1\n",
       "1   [[[0.09411764705882353, 0.3333333333333333, 0....     1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf9d0062",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_size[0], img_size[1], 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bce99566",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e59b76f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_train['images']\n",
    "y = data_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b09f306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [tf.convert_to_tensor(img) for img in x]\n",
    "x = tf.stack(x)\n",
    "y = [tf.convert_to_tensor(val) for val in y]\n",
    "y = tf.strings.to_number(y,out_type=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cee7c37d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.7870 - accuracy: 0.4550\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 1s 260ms/step - loss: 0.6866 - accuracy: 0.5200\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 1s 266ms/step - loss: 0.6961 - accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 1s 261ms/step - loss: 0.6843 - accuracy: 0.5400\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.6805 - accuracy: 0.5800\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 1s 266ms/step - loss: 0.6724 - accuracy: 0.6100\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 1s 269ms/step - loss: 0.6650 - accuracy: 0.6150\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 1s 245ms/step - loss: 0.6471 - accuracy: 0.6550\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 0.6159 - accuracy: 0.7150\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 1s 369ms/step - loss: 0.5978 - accuracy: 0.6900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f5830ff460>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,batch_size=128,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba7fc2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(data):\n",
    "    test_images = [tf.convert_to_tensor(images) for images in data['images'].values]\n",
    "    test_images = tf.stack(test_images)\n",
    "\n",
    "    test_labels = tf.convert_to_tensor(data['label'].values)\n",
    "    test_labels = tf.strings.to_number(test_labels, out_type=tf.float32)\n",
    "\n",
    "    loss, accuracy = model.evaluate(test_images, test_labels)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfcd8e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6583 - accuracy: 0.6082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6082473993301392"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bbb81656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_single_image(image_path):\n",
    "    lis = []\n",
    "    image = cv2.imread(image_path)\n",
    "    resized_image = cv2.resize(image,(64,64))\n",
    "    normalized_image = resized_image / 255.0\n",
    "    lis.append(normalized_image)\n",
    "    return lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7dce4e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_and_preprocess_single_image(\"C://Users//pajag//OneDrive//Desktop//img apple & tomato//test//apples//img_p1_70.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36a00750",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = [tf.convert_to_tensor(img) for img in img]\n",
    "img1 = tf.stack(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0aef4ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 64, 64, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3431c72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5065b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple\n"
     ]
    }
   ],
   "source": [
    "if pred < 0.5:\n",
    "    print('apple')\n",
    "else:\n",
    "    print('tomato')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
